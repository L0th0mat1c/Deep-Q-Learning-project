{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning Grid Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==2.2.1 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: backcall==0.2.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.2.1)\n",
      "Requirement already satisfied: cmake==3.26.1 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (3.26.1)\n",
      "Requirement already satisfied: comm==0.1.3 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.1.3)\n",
      "Requirement already satisfied: contourpy==1.0.7 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (1.0.7)\n",
      "Requirement already satisfied: cycler==0.11.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: debugpy==1.6.6 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.6.6)\n",
      "Requirement already satisfied: decorator==5.1.1 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (5.1.1)\n",
      "Requirement already satisfied: executing==1.2.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (1.2.0)\n",
      "Requirement already satisfied: Farama-Notifications==0.0.4 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (0.0.4)\n",
      "Requirement already satisfied: fonttools==4.39.3 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (4.39.3)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (0.28.1)\n",
      "Requirement already satisfied: ipykernel==6.22.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (6.22.0)\n",
      "Requirement already satisfied: ipython==8.11.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (8.11.0)\n",
      "Requirement already satisfied: jax-jumpy==1.0.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (1.0.0)\n",
      "Requirement already satisfied: jedi==0.18.2 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (0.18.2)\n",
      "Requirement already satisfied: jupyter_client==8.1.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (8.1.0)\n",
      "Requirement already satisfied: jupyter_core==5.3.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (5.3.0)\n",
      "Requirement already satisfied: kiwisolver==1.4.4 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (1.4.4)\n",
      "Requirement already satisfied: matplotlib==3.7.1 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (3.7.1)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 22)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (1.5.6)\n",
      "Requirement already satisfied: numpy==1.24.2 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 24)) (1.24.2)\n",
      "Requirement already satisfied: packaging==23.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 25)) (23.0)\n",
      "Requirement already satisfied: pandas==2.0.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 26)) (2.0.0)\n",
      "Requirement already satisfied: parso==0.8.3 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 27)) (0.8.3)\n",
      "Requirement already satisfied: pexpect==4.8.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 28)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 29)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==9.5.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 30)) (9.5.0)\n",
      "Requirement already satisfied: platformdirs==3.2.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 31)) (3.2.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.38 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 32)) (3.0.38)\n",
      "Requirement already satisfied: psutil==5.9.4 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 33)) (5.9.4)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 34)) (0.7.0)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 35)) (0.2.2)\n",
      "Requirement already satisfied: pygame==2.1.3 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 36)) (2.1.3)\n",
      "Requirement already satisfied: Pygments==2.14.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 37)) (2.14.0)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 38)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 39)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2023.3 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 40)) (2023.3)\n",
      "Requirement already satisfied: pyzmq==25.0.2 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 41)) (25.0.2)\n",
      "Requirement already satisfied: scipy==1.10.1 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 42)) (1.10.1)\n",
      "Requirement already satisfied: six==1.16.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 43)) (1.16.0)\n",
      "Requirement already satisfied: stack-data==0.6.2 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 44)) (0.6.2)\n",
      "Requirement already satisfied: tornado==6.2 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 45)) (6.2)\n",
      "Requirement already satisfied: traitlets==5.9.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 46)) (5.9.0)\n",
      "Requirement already satisfied: typing_extensions==4.5.0 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 47)) (4.5.0)\n",
      "Requirement already satisfied: tzdata==2023.3 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 48)) (2023.3)\n",
      "Requirement already satisfied: wcwidth==0.2.6 in /home/louis/Epitech/MSC2/T-AIA-902-TLS_6/Q-Learning/lib/python3.11/site-packages (from -r requirements.txt (line 49)) (0.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "import numpy as np\n",
    "from random import randint, uniform\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charging environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Taxi-v3\", render_mode=\"ansi\")\n",
    "# We can test render_mode to 'human' in the future\n",
    "\n",
    "env.reset()\n",
    "print(env.render())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filled square represents the taxi, which is yellow without a passenger and green with a passenger.  \n",
    "The pipe (\"|\") represents a wall which the taxi cannot cross.  \n",
    "R, G, Y, B are the possible pickup and destination locations. The blue letter represents the current passenger pick-up location, and the purple letter is the current destination.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space Discrete(6)\n",
      "State Space Discrete(500)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Action Space {env.action_space}\")\n",
    "print(f\"State Space {env.observation_space}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 6 actions inside the environment:\n",
    "- **0**: south\n",
    "- **1**: north\n",
    "- **2**: east\n",
    "- **3**: west\n",
    "- **4**: pickup\n",
    "- **5**: dropoff\n",
    "\n",
    "And 500 possible states:\n",
    "- **5x5** grid\n",
    "- **4** destinations\n",
    "- **5** passenger locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: 493\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current state: {env.s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 493, -1, False)],\n",
       " 1: [(1.0, 393, -1, False)],\n",
       " 2: [(1.0, 493, -1, False)],\n",
       " 3: [(1.0, 473, -1, False)],\n",
       " 4: [(1.0, 493, -10, False)],\n",
       " 5: [(1.0, 493, -10, False)]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[env.s]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each action in this state, we have:\n",
    "- **probability**: always at 1.0 in this env\n",
    "- **nextstate**: the next state if the agent takes this action\n",
    "- **reward**: the reward (positive or negative) gained after performing this action\n",
    "- **done**: boolean at True when a passenger is correctly dropof"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implementing the Q-Learning algorithm, we will be through those steps:\n",
    "\n",
    "- Initialize the Q-table by all zeros.\n",
    "- Start exploring actions: For each state, select any one among all possible actions for the current state (S).\n",
    "- Travel to the next state (S') as a result of that action (a).\n",
    "- For all possible actions from the state (S') select the one with the highest Q-value.\n",
    "- Update Q-table values using the equation.\n",
    "- Set the next state as the current state.\n",
    "- If goal state is reached, then end and repeat the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - Firsts tests\n",
    "# EPSILON_LIST = np.arange(0.1, 1, 0.1)\n",
    "# ALPHA_LIST = np.arange(0.1, 1, 0.1)\n",
    "# GAMMA_LIST = np.arange(0.1, 1, 0.1)\n",
    "\n",
    "# Hyperparameters - Second tests\n",
    "EPSILON_LIST = np.arange(0.15, 0.25, 0.01)\n",
    "ALPHA_LIST = np.arange(0.05, 0.15, 0.01)\n",
    "GAMMA_LIST = np.arange(0.35, 0.45, 0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For grid search pruposes, we scan all values of hyperparameters from 0 to 1, with steps of 0.1  \n",
    "With a second test we can search with better values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('results_grid-search_v2.csv', 'a') as results:\n",
    "#     results.write(\"Epsilon;Alpha;Gamma;Epochs_learn;Penalties_learn;Epochs_eval;Penalties_eval;Worked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Phase\n",
      "\rEpsilon: 0.25 | Alpha: 0.13 | Gamma: 0.36 => Episode: 99\n"
     ]
    }
   ],
   "source": [
    "# Grid search\n",
    "for EPSILON in EPSILON_LIST:\n",
    "    for ALPHA in ALPHA_LIST:\n",
    "        for GAMMA in GAMMA_LIST:\n",
    "            # Q-table\n",
    "            q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "            \n",
    "            # Fields\n",
    "            penalties_learn = epochs_learn = 0\n",
    "            penalties_eval = epochs_eval = 0\n",
    "            worked = True\n",
    "            \n",
    "            # Learning\n",
    "            for i in range(100_000):\n",
    "                # Reset the environment\n",
    "                state = env.reset()[0]\n",
    "                \n",
    "                # initialize fields\n",
    "                done = False\n",
    "                \n",
    "                # Start the episode process\n",
    "                while not done:\n",
    "                    # Deciding which action to perform\n",
    "                    if uniform(0, 1) < EPSILON:\n",
    "                        action = env.action_space.sample() # Exploration\n",
    "                    else:\n",
    "                        action = np.argmax(q_table[state]) # Exploitation\n",
    "                    \n",
    "                    # Performing action inside the environment\n",
    "                    next_state, reward, done, info, _ = env.step(action)\n",
    "                    \n",
    "                    # Getting usefull fields to calculate the new value of Q-Table\n",
    "                    old_value = q_table[state, action]\n",
    "                    next_max = np.max(q_table[next_state])\n",
    "                    \n",
    "                    # Calculate new value\n",
    "                    new_value = (1 - ALPHA) * old_value + ALPHA * (reward + GAMMA * next_max)\n",
    "                    \n",
    "                    q_table[state, action] = new_value\n",
    "                    \n",
    "                    # Getting stats when the agent performed illegal action (pickup or dropoff)\n",
    "                    penalties_learn += 1 if reward == -10 else 0\n",
    "                    \n",
    "                    # Updating state\n",
    "                    state = next_state\n",
    "                    \n",
    "                    epochs_learn += 1\n",
    "                    \n",
    "                    if epochs_learn > 10_000_000:\n",
    "                        worked = False\n",
    "                        done = True\n",
    "                \n",
    "                # Display the number of episode\n",
    "                if i % 100 == 0:\n",
    "                    clear_output(wait=True)\n",
    "                    print(f\"Learning Phase\\n\\rEpsilon: {EPSILON} | Alpha: {ALPHA} | Gamma: {GAMMA} => Episode: {i}\")\n",
    "            \n",
    "            # Evaluate\n",
    "            if worked:\n",
    "                for i in range(100):\n",
    "                    # Print\n",
    "                    clear_output(wait=True)\n",
    "                    print(f\"Evaluation Phase\\n\\rEpsilon: {EPSILON} | Alpha: {ALPHA} | Gamma: {GAMMA} => Episode: {i}\")\n",
    "                    \n",
    "                    # Reset the environment\n",
    "                    state = env.reset()[0]\n",
    "                    \n",
    "                    # Initialize fields\n",
    "                    done = False\n",
    "                    \n",
    "                    # Start the episode process\n",
    "                    while not done:\n",
    "                        # Only Exploitation during the evaluation phase\n",
    "                        action = np.argmax(q_table[state])\n",
    "                        \n",
    "                        # Performing action inside the environment\n",
    "                        state, reward, done, info, _ = env.step(action)\n",
    "                        \n",
    "                        # Getting stats when the agent performed illegal action (pickup or dropoff)\n",
    "                        penalties_eval += 1 if reward == -10 else 0\n",
    "                        \n",
    "                        epochs_eval += 1\n",
    "                        \n",
    "                        if epochs_eval > 100_000:\n",
    "                            worked = False\n",
    "                            done = True\n",
    "            \n",
    "            # Adding stats inside the csv file\n",
    "            with open('results_grid-search_v2.csv', 'a') as results:\n",
    "                results.write(f\"\\r{EPSILON};{ALPHA};{GAMMA};{epochs_learn};{penalties_learn};{epochs_eval};{penalties_eval};{worked}\")\n",
    "\n",
    "print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q-Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b2a4a885a2aba7b1b4c4c8ed754d25a01b55f8805396ed576e88b91d2fc67c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
